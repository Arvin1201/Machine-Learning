0825回归算法&KNN
-----------------------------------------------
算法模型构建的过程中，需要注意一下两个方面：
  -1. 算法模型的误差不能过大(预测值和实际值之间的误差不能过大)
  -2. 算法模型不能太复杂

如果模型的误差较大，也就是预测值和实际值之间的差值比较大的情况下：
  -1. 如果是训练数据集存在该问题：
     表示此时模型训练的不够好，模型没有学习到数据的特征信息，也就是没有找到特征属性和目标属性之间的映射关系。
	 问题描述：当前称模型存在欠拟合的问题
	 导致原因：
	   -1. 算法的学习能力比较弱
	   -2. 数据量样本少
	   -3. 有用的特征属性数目太少
	 解决方案：
	   -1. 换一种学习能力比较强的算法，eg：svm、集成算法....
	   -2. 增加样本数据(基于现有数据产生模拟的虚假数据、收集更多的数据)
	   -3. 增加特征属性的数目(结合业务产生更多的有效特征、将现有的特征属性做一个融合从而产生更多的特征属性)
	   
  -2. 如果仅是在测试数据集上存在该问题： --> 过拟合

如果模型在训练集上的效果不错，但是在测试集上的效果非常差，或者说训练集上的效果和测试集上的效果不匹配：
   这种情况下，我们认为模型存在过拟合；也就是说模型的学习能力太强了，把训练数据的特征学习的太细了，导致学习了某些只存在于训练集中，而在测试集或者真实数据中不存在的特征信息
   直白来讲：模型的学习能力太强，就可能存在过拟合的情况
   产生原因：
     -1. 数据样本少
	 -2. 模型的学习能力太强(模型比较复杂)
	 -3. 做了太多的特征的增维操作
   解决方案：
     -1. 增加数据样本(基于现有数据产生模拟的虚假数据、收集更多的数据)
	 -2. 换一个算法模型或者在模型训练过程中，加入正则化项系数，限制模型过拟合，正则化主要分为：L1和L2
	 -3. 不要做太多的、太深的维度的增维操作
  
多项式扩展：
  属于增维的一种方式，通过这种方式可以将数据映射到高维度空间变成线性可分的数据
  功能：将低维空间上的数据通过多项式的组合，映射到高维空间中
  效果：可以将低维空间的非线性的数据转换到高维空间中变成线性数据
  方式(sklearn中的多项式扩展的API的效果)：
    原始数据: (2,3)
	如果做一个最高次项为2的多项式变换，最终结果为: (1,2,3,4,6,9)
	如果做一个最高次项为3的多项式转换，最终结果为：(1,2,3,4,6,9,8,12,18,27)
	如果做一个最高次项为4的多项式转换，最终结果为：(1,2,3,4,6,9,8,12,18,27,16,24,36,54,81)
  
多项式扩展+线性回归 ---> 多项式线性回归：
  其实相当于首先对数据做一个维度的扩展，然后对扩展之后的特征属性矩阵X做一个线性回归的算法模型的训练。
  eg:
    原特征属性: x1, x2, x3
	做一个2次的多项式变换，结果为: 1, x1, x2, x3, x1*x1, x1*x2, x1*x3, x2*x2, x2*x3, x3*x3, 其实相当于构建一个新的特征属性维度空间，eg: z1, z2, z3, z4, z5, z6, z7, z8, z9, z10
	基于转换的结果做一个线性回归: h(z)
----------------------------------------------- 
稀疏就是训练出来得到的模型参数中有很多参数值都是0，这个我们就叫做稀疏解；稀疏解的作用主要是用于特征选择的，因为参数为0所对应的特征相当于没有决策能力，不会影响y的取值，既然这样，我们可以将这些为0所对应的特征删除
-----------------------------------------------
模型参数：
  需要在训练数据集上通过某种给定的方式找出的模型参数，也就是说这个模型参数的求解就是我们经常所说的模型学习，eg：线性回归中的θ....
超参：
  在模型训练中需要使用到的参数值，但是该参数值需要开发人员给定的。eg：Ridge API中的alpha....
  给定超参数的方式：
    -1. 可以根据算法的特性、业务背景以及经验，来给定一个比较适合的值
	-2. 通过sklearn提供的交叉验证的方式来选择最优的参数
	-3. 通过网格交叉验证的方式选择最优参数
	

K折交叉验证(K-Fold):
  是指在模型训练过程中，主要用于模型参数选择的一种方式。
  步骤：
    -1. 将fit传入的train的训练数据平均分成K份
	-2. 对于当前模型参数，使用其中的K-1份数据作为模型的训练数据，使用另外一份数据作为模型的验证数据集，得到当前模型在当前数据划分情况下的评估指标(默认就是模型自带的scoreAPI)；迭代所有的数据组成方式，得到当前模型在当前所有划分组合数据集上的K个评估指标，然后将这K个指标求均值，作为当前模型参数在训练数据train上的效果衡量值s
	-3. 使用上一步，遍历所有的模型参数取值的可能，得到所有模型的衡量值s
	-4. 使用模型效果衡量值最好的那个对应的算法模型作为最终的模型
  eg: RidgeCV(alphas=[0.1, 0.2, 0.3], cv=5)
	备注：将所有的训练数据划分为5份，编号为1,2,3,4,5
    -1. 当前模型参数: alpha=0.1;
	  --1. 训练数据集: 1,2,3,4；验证集: 5；模型效果s11
	  --2. 训练数据集: 1,2,3,5；验证集: 4；模型效果s12
	  --3. 训练数据集: 1,2,4,5；验证集: 3；模型效果s13
	  --4. 训练数据集: 1,3,4,5；验证集: 2；模型效果s14
	  --5. 训练数据集: 2,3,4,5；验证集: 1；模型效果s15
	  --6. 求score的均值: s1 = (s11 + s12 + s13 + s14 + s15) / 5
	  
	-2. 当前模型参数: alpha=0.2;
	  --1. 训练数据集: 1,2,3,4；验证集: 5；模型效果s21
	  --2. 训练数据集: 1,2,3,5；验证集: 4；模型效果s22
	  --3. 训练数据集: 1,2,4,5；验证集: 3；模型效果s23
	  --4. 训练数据集: 1,3,4,5；验证集: 2；模型效果s24
	  --5. 训练数据集: 2,3,4,5；验证集: 1；模型效果s25
	  --6. 求score的均值: s2 = (s21 + s22 + s23 + s24 + s25) / 5
	-3. 当前模型参数: alpha=0.3;
	  --1. 训练数据集: 1,2,3,4；验证集: 5；模型效果s31
	  --2. 训练数据集: 1,2,3,5；验证集: 4；模型效果s32
	  --3. 训练数据集: 1,2,4,5；验证集: 3；模型效果s33
	  --4. 训练数据集: 1,3,4,5；验证集: 2；模型效果s34
	  --5. 训练数据集: 2,3,4,5；验证集: 1；模型效果s35
	  --6. 求score的均值: s3 = (s31 + s32 + s33 + s34 + s35) / 5
	-4. 在这三组参数中，根据s1\s2\s3的取值，选择一个最大的作为最优模型。
  eg: ElasticNetCV(alphas=[0.1,0.2,0.3], l1_ratio=[0.5,0.8], cv=5)
    备注：将所有的训练数据划分为5份，编号为1,2,3,4,5
    -1. 当前模型参数: alpha=0.1, l1_ratio=0.5;
	-2. 当前模型参数: alpha=0.1, l1_ratio=0.8;
	-3. 当前模型参数: alpha=0.2, l1_ratio=0.5; 
	-4. 当前模型参数: alpha=0.2, l1_ratio=0.8;
	-5. 当前模型参数: alpha=0.3, l1_ratio=0.5;
	-6. 当前模型参数: alpha=0.3, l1_ratio=0.8;

留一交叉验证：
  其实就是n折交叉(n是样本数)
  含义：使用n-1条样本作为训练数据训练模型，使用其他的另外一条数据作为模型验证集，迭代构建n次，综合均值评分作为模型的效果衡量指标



  